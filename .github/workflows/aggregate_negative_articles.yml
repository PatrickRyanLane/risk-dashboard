name: Aggregate Negative Articles + Send Crisis Alerts

on:
  schedule:
    - cron: '30 12 * * *'  # 12:30 UTC daily
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

jobs:
  aggregate:
    runs-on: ubuntu-latest
    env:
      GCS_BUCKET: risk-dashboard
      PYTHONPATH: ${{ github.workspace }}
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          sparse-checkout: |
            requirements.txt
            scripts/
            storage_utils.py
            .github/
          sparse-checkout-cone-mode: false

      - name: Verify checkout
        run: |
          echo "ðŸ“‚ Workspace: ${{ github.workspace }}"
          ls -la
          echo "âœ… storage_utils.py exists:" && test -f storage_utils.py && echo "YES" || echo "NO"
      
      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCS_SERVICE_ACCOUNT_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Run negative articles aggregation (â†’ GCS)
        run: |
          echo "ðŸ“„ Aggregating negative articles from last 90 days..."
          python scripts/aggregate_negative_articles.py \
            --days-back 90 \
            --bucket "$GCS_BUCKET"

      - name: Send Crisis Alerts (Slack + Salesforce)
        env:
          SF_USERNAME: ${{ secrets.SF_USERNAME }}
          SF_PASSWORD: ${{ secrets.SF_PASSWORD }}
          SF_SECURITY_TOKEN: ${{ secrets.SF_SECURITY_TOKEN }}
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_PROVIDER: ${{ vars.LLM_PROVIDER }}
          LLM_MODEL: ${{ vars.LLM_MODEL }}
          LLM_MAX_CALLS: ${{ vars.LLM_MAX_CALLS }}
          LLM_SUMMARY_MAX_CALLS: ${{ vars.LLM_SUMMARY_MAX_CALLS }}
          SERP_TOP_STORIES_REQUIRED: ${{ vars.SERP_TOP_STORIES_REQUIRED || '1' }}
          SERP_TOP_STORIES_NEG_MIN: ${{ vars.SERP_TOP_STORIES_NEG_MIN || '2' }}
          SERP_GATE_MIN: ${{ vars.SERP_GATE_MIN || '1' }}
          SERP_GATE_DAYS: ${{ vars.SERP_GATE_DAYS || '2' }}
          SERP_GATE_DEBUG: ${{ vars.SERP_GATE_DEBUG || '1' }}
        run: |
          echo "ðŸš€ Checking for crises and sending alerts..."
          python scripts/send_crisis_alerts.py --bucket "$GCS_BUCKET"
      
      - name: Summary
        if: always()
        run: |
          echo "### Negative Articles Aggregation Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "â˜ï¸ **Bucket:** gs://$GCS_BUCKET" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "#### Output file:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          gsutil ls -l "gs://$GCS_BUCKET/data/daily_counts/negative-articles-summary.csv" >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "File not found" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

          echo "#### Top 10 Brand Risk Scores:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          gsutil cat "gs://$GCS_BUCKET/data/daily_counts/negative-articles-summary.csv" | \
            python3 -c 'import sys,csv;rows=list(csv.DictReader(sys.stdin));\n\
            rows=[r for r in rows if r.get(\"date\")];\n\
            max_date=max(r[\"date\"] for r in rows);\n\
            rows=[r for r in rows if (r.get(\"article_type\") == \"brand\" and r.get(\"risk_score\") not in (None, \"\") and r.get(\"date\")==max_date)];\n\
            rows.sort(key=lambda r: float(r.get(\"risk_score\", 0) or 0), reverse=True);\n\
            top=rows[:10];\n\
            print(f\"date={max_date} | company | score | neg | serp\");\n\
            for r in top:\n\
                print(f\"{r.get('date','')} | {r.get('company','')} | {float(r.get('risk_score',0) or 0):.1f} | {r.get('negative_count','')} | {r.get('serp_neg_uncontrolled','')}\")' \
            >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No brand risk score data" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

          echo "#### Top 10 CEO Risk Scores:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          gsutil cat "gs://$GCS_BUCKET/data/daily_counts/negative-articles-summary.csv" | \
            python3 -c 'import sys,csv;rows=list(csv.DictReader(sys.stdin));\n\
            rows=[r for r in rows if r.get(\"date\")];\n\
            max_date=max(r[\"date\"] for r in rows);\n\
            rows=[r for r in rows if (r.get(\"article_type\") == \"ceo\" and r.get(\"risk_score\") not in (None, \"\") and r.get(\"date\")==max_date)];\n\
            rows.sort(key=lambda r: float(r.get(\"risk_score\", 0) or 0), reverse=True);\n\
            top=rows[:10];\n\
            print(f\"date={max_date} | company | ceo | score | neg | serp\");\n\
            for r in top:\n\
                print(f\"{r.get('date','')} | {r.get('company','')} | {r.get('ceo','')} | {float(r.get('risk_score',0) or 0):.1f} | {r.get('negative_count','')} | {r.get('serp_neg_uncontrolled','')}\")' \
            >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No CEO risk score data" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
